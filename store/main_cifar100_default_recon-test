
(base) valeriya_khan@instance-1:~$
(base) valeriya_khan@instance-1:~$ conda activate contle
(contle) valeriya_khan@instance-1:~$ python main.py --experiment=CIFAR100 --scenario=class --brain-inspired --s
eed=0
python: can't open file '/home/valeriya_khan/main.py': [Errno 2] No such file or directory
(contle) valeriya_khan@instance-1:~$ cd continual-learning
(contle) valeriya_khan@instance-1:~/continual-learning$ python main.py --experiment=CIFAR100 --scenario=class -
-brain-inspired --seed=0
CUDA is used


 ***************************** LOAD DATA ******************************
Files already downloaded and verified
 --> CIFAR100: 'train'-dataset consisting of 50000 samples
Files already downloaded and verified
 --> CIFAR100: 'test'-dataset consisting of 10000 samples


 ********************** DEFINE FEATURE EXTRACTOR **********************
 --> loaded checkpoint of C3-5x16-bn-e100 from ./store/models
-------------------------------------------------------
FeatureExtractor(
  (convE): ConvLayers(
    (convLayer1): conv_layer(
      (conv): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (nl): ReLU()
    )
    (convLayer2): conv_layer(
      (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (nl): ReLU()
    )
    (convLayer3): conv_layer(
      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (nl): ReLU()
    )
    (convLayer4): conv_layer(
      (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (nl): ReLU()
    )
    (convLayer5): conv_layer(
      (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (nl): Identity()
    )
    (pooling): Identity()
  )
)
-------------------------------------------------------
--> this network has 393088 parameters (~0.4 million)
       of which: - learnable: 0 (~0.0 million)
                 - fixed: 393088 (~0.4 million)


 ***************** PUT DATA TRHOUGH FEATURE EXTRACTOR *****************
<TRAINSET> | dataset 10/10 |: 100%|████████████████████████████████████████████| 10/10 [00:18<00:00,  1.90s/it]
<TESTSET>  | dataset 10/10 |: 100%|████████████████████████████████████████████| 10/10 [00:03<00:00,  2.88it/s]


 *********************** DEFINE THE CLASSIFIER ************************
-------------------------------------------------------
CondVAE(
  (convE): ConvLayers(
    (pooling): Identity()
  )
  (flatten): Flatten()
  (fcE): MLP(
    (fcLayer1): fc_layer(
      (linear): LinearExcitability(in_features=1024, out_features=2000)
      (nl): ReLU()
    )
    (fcLayer2): fc_layer(
      (linear): LinearExcitability(in_features=2000, out_features=2000)
      (nl): ReLU()
    )
  )
  (toZ): fc_layer_split(
    (mean): fc_layer(
      (linear): LinearExcitability(in_features=2000, out_features=100)
    )
    (logvar): fc_layer(
      (linear): LinearExcitability(in_features=2000, out_features=100)
    )
  )
  (classifier): fc_layer(
    (linear): LinearExcitability(in_features=2000, out_features=100)
  )
  (fromZ): fc_layer_fixed_gates(
    (linear): LinearExcitability(in_features=100, out_features=2000)
    (nl): ReLU()
  )
  (fcD): MLP_gates(
    (fcLayer1): fc_layer_fixed_gates(
      (linear): LinearExcitability(in_features=2000, out_features=2000)
      (nl): ReLU()
    )
    (fcLayer2): fc_layer(
      (linear): LinearExcitability(in_features=2000, out_features=1024)
    )
  )
  (to_image): Reshape(channels = 256)
  (convD): DeconvLayers()
)
-------------------------------------------------------
--> this network has 12925224 parameters (~12.9 million)
       of which: - learnable: 12925224 (~12.9 million)
                 - fixed: 0 (~0.0 million)


************************** PARAMETER STAMP ***************************
 --> problem:       CIFAR100-N10-class
 --> model:         HC3-5x16-bn--CondVAE=F-1024x2000x2000--z100-GMM100pc-c100_cg0.7
 --> train-params:  i5000-lr0.0001-b256-pCvE-e100-adam-all-MSE
 --> replay:        generative-KD2.0
CIFAR100-N10-class--HC3-5x16-bn--CondVAE=F-1024x2000x2000--z100-GMM100pc-c100_cg0.7--i5000-lr0.0001-b256-pCvE-e
100-adam-all-MSE--generative-KD2.0


****************************** TRAINING ******************************
  <VAE>      | Context: 1/10 | training loss: 0.119 | training accuracy: 1.0 |: 100%|█| 5000/5000 [04:41<00:00,
 - Context 1: 0.7900
=> average accuracy over all 1 contexts: 0.7900


 - Context 1: 1.0861
=> reconstruction loss over all 1 contexts: 1.0861


  <VAE>      | Context: 2/10 | training loss: 0.364 | training accuracy: 1.0 |: 100%|█| 5000/5000 [08:03<00:00,
 - Context 1: 0.5970
 - Context 2: 0.7260
=> average accuracy over all 2 contexts: 0.6615


 - Context 1: 1.1227
 - Context 2: 1.1091
=> reconstruction loss over all 2 contexts: 1.1159


  <VAE>      | Context: 3/10 | training loss: 0.773 | training accuracy: 1.0 |: 100%|█| 5000/5000 [08:02<00:00,
 - Context 1: 0.3820
 - Context 2: 0.5260
 - Context 3: 0.7630
=> average accuracy over all 3 contexts: 0.5570


 - Context 1: 1.1996
 - Context 2: 1.2510
 - Context 3: 0.9612
=> reconstruction loss over all 3 contexts: 1.1373


  <VAE>      | Context: 4/10 | training loss: 1.3 | training accuracy: 1.0 |: 100%|█| 5000/5000 [08:02<00:00, 1
 - Context 1: 0.3010
 - Context 2: 0.2800
 - Context 3: 0.5710
 - Context 4: 0.7310
=> average accuracy over all 4 contexts: 0.4708


 - Context 1: 1.2694
 - Context 2: 1.4111
 - Context 3: 1.1664
 - Context 4: 1.0523
=> reconstruction loss over all 4 contexts: 1.2248


  <VAE>      | Context: 5/10 | training loss: 1.43 | training accuracy: 1.0 |: 100%|█| 5000/5000 [08:01<00:00,
 - Context 1: 0.2310
 - Context 2: 0.1990
 - Context 3: 0.4190
 - Context 4: 0.4650
 - Context 5: 0.7380
=> average accuracy over all 5 contexts: 0.4104


 - Context 1: 1.3446
 - Context 2: 1.5569
 - Context 3: 1.3312
 - Context 4: 1.3057
 - Context 5: 1.0446
=> reconstruction loss over all 5 contexts: 1.3166


  <VAE>      | Context: 6/10 | training loss: 1.37 | training accuracy: 1.0 |: 100%|█| 5000/5000 [08:02<00:00,
 - Context 1: 0.1740
 - Context 2: 0.1490
 - Context 3: 0.3870
 - Context 4: 0.3620
 - Context 5: 0.5130
 - Context 6: 0.7400
=> average accuracy over all 6 contexts: 0.3875


 - Context 1: 1.4105
 - Context 2: 1.7010
 - Context 3: 1.5302
 - Context 4: 1.4148
 - Context 5: 1.2935
 - Context 6: 1.0398
=> reconstruction loss over all 6 contexts: 1.3983


  <VAE>      | Context: 7/10 | training loss: 1.25 | training accuracy: 1.0 |: 100%|█| 5000/5000 [08:00<00:00,
 - Context 1: 0.1660
 - Context 2: 0.1300
 - Context 3: 0.3050
 - Context 4: 0.2900
 - Context 5: 0.4040
 - Context 6: 0.5600
 - Context 7: 0.7390
=> average accuracy over all 7 contexts: 0.3706


 - Context 1: 1.3997
 - Context 2: 1.8087
 - Context 3: 1.7812
 - Context 4: 1.5842
 - Context 5: 1.3959
 - Context 6: 1.2595
 - Context 7: 0.9129
=> reconstruction loss over all 7 contexts: 1.4489


  <VAE>      | Context: 8/10 | training loss: 1.28 | training accuracy: 1.0 |: 100%|█| 5000/5000 [08:01<00:00,
 - Context 1: 0.1430
 - Context 2: 0.1200
 - Context 3: 0.2500
 - Context 4: 0.2370
 - Context 5: 0.3330
 - Context 6: 0.4250
 - Context 7: 0.4330
 - Context 8: 0.7040
=> average accuracy over all 8 contexts: 0.3306


 - Context 1: 1.4398
 - Context 2: 1.9365
 - Context 3: 1.9275
 - Context 4: 1.7434
 - Context 5: 1.5013
 - Context 6: 1.3937
 - Context 7: 1.0958
 - Context 8: 0.9618
=> reconstruction loss over all 8 contexts: 1.5000


  <VAE>      | Context: 9/10 | training loss: 1.32 | training accuracy: 1.0 |: 100%|█| 5000/5000 [08:01<00:00,
 - Context 1: 0.1030
 - Context 2: 0.0750
 - Context 3: 0.2020
 - Context 4: 0.1630
 - Context 5: 0.2620
 - Context 6: 0.3060
 - Context 7: 0.3390
 - Context 8: 0.4760
 - Context 9: 0.7460
=> average accuracy over all 9 contexts: 0.2969


 - Context 1: 1.4706
 - Context 2: 2.0235
 - Context 3: 2.1107
 - Context 4: 1.9037
 - Context 5: 1.6471
 - Context 6: 1.5351
 - Context 7: 1.2253
 - Context 8: 1.1840
 - Context 9: 1.1544
=> reconstruction loss over all 9 contexts: 1.5838


  <VAE>      | Context: 10/10 | training loss: 1.43 | training accuracy: 1.0 |: 100%|█| 5000/5000 [08:01<00:00,
 - Context 1: 0.1010
 - Context 2: 0.0590
 - Context 3: 0.1770
 - Context 4: 0.0910
 - Context 5: 0.1780
 - Context 6: 0.1740
 - Context 7: 0.2420
 - Context 8: 0.2730
 - Context 9: 0.3820
 - Context 10: 0.7850
=> average accuracy over all 10 contexts: 0.2462


 - Context 1: 1.4932
 - Context 2: 2.1123
 - Context 3: 2.2501
 - Context 4: 2.1020
 - Context 5: 1.7935
 - Context 6: 1.6871
 - Context 7: 1.3727
 - Context 8: 1.3353
 - Context 9: 1.4079
 - Context 10: 1.0527
=> reconstruction loss over all 10 contexts: 1.6607


 --> saved model mM-CIFAR100-N10-class--HC3-5x16-bn--CondVAE=F-1024x2000x2000--z100-GMM100pc-c100_cg0.7--i5000-
lr0.0001-b256-pCvE-e100-adam-all-MSE--generative-KD2.0 to ./store/models


***************************** EVALUATION *****************************

 Accuracy of final model on test-set:
 - Context 1: 0.1010
 - Context 2: 0.0590
 - Context 3: 0.1770
 - Context 4: 0.0910
 - Context 5: 0.1780
 - Context 6: 0.1740
 - Context 7: 0.2420
 - Context 8: 0.2730
 - Context 9: 0.3820
 - Context 10: 0.7850
=> average accuracy over all 10 contexts: 0.2462


(contle) valeriya_khan@instance-1:~/continual-learning$
